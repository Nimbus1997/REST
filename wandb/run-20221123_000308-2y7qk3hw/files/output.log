create web directory ./checkpoints/ellen_dwt_uresnet1_1_test0/web...
learning rate 0.0002000 -> 0.0002000
/home/guest1/.conda/envs/ellen/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
> /home/guest1/ellen_code/pytorch-CycleGAN-and-pix2pix_ellen/models/cycle_gan_model.py(188)optimize_parameters()
-> self.set_requires_grad([self.netD_A, self.netD_B], False)  # Ds require no gradients when optimizing Gs9981


[?2004h(Pdb) self.fake_B
tensor([[[[ 1.2902e-03,  1.0815e-02,  6.8373e-04,  ...,  9.5553e-04,
           -3.7607e-03, -3.1917e-03],
          [ 6.4032e-03, -5.7597e-03,  1.5315e-02,  ...,  1.9793e-02,
           -5.4536e-04, -3.4145e-03],
          [-1.2168e-03,  1.1389e-02, -1.3378e-03,  ...,  3.4824e-03,
            6.6835e-03,  1.3621e-02],
          ...,
          [ 6.9668e-03, -1.1563e-02,  1.8775e-03,  ..., -1.0910e-02,
           -3.5259e-03, -1.4522e-03],
          [-3.5996e-03, -2.6105e-02, -1.0814e-03,  ...,  2.4250e-02,
            5.2571e-03,  1.1525e-04],
          [ 1.7792e-03, -2.7617e-03,  1.5920e-03,  ...,  1.6205e-03,
           -2.1714e-03, -1.4928e-03]],
         [[-1.4385e-04,  6.7119e-04,  7.0559e-03,  ...,  2.0082e-03,
           -2.9971e-03, -7.2816e-03],
          [ 2.1178e-03,  7.3012e-04, -1.4821e-02,  ...,  8.9955e-05,
           -1.0242e-02, -7.0947e-04],
          [-7.6067e-03, -1.8224e-02, -9.4410e-03,  ..., -1.7001e-02,
           -1.6991e-02, -3.1731e-03],
          ...,
          [ 5.1037e-03, -1.8670e-02, -3.3929e-02,  ...,  1.8082e-02,
           -1.6420e-02, -1.8611e-03],
          [-1.0862e-02, -1.1919e-02, -3.1962e-03,  ...,  8.6255e-03,
            1.3440e-02,  1.1923e-03],
          [-1.9189e-02, -9.0018e-03, -1.2524e-03,  ...,  3.3666e-03,
           -5.6108e-03,  3.9099e-04]],
         [[-7.2490e-04, -4.2398e-03, -5.8729e-03,  ...,  5.5979e-03,
           -1.0596e-02, -1.0230e-02],
          [ 7.0373e-03, -4.7690e-03,  2.8311e-02,  ..., -2.5542e-02,
            1.2273e-02, -1.1982e-02],
          [ 1.7888e-03, -1.0186e-02, -1.0150e-02,  ..., -1.7447e-02,
            1.6524e-02,  2.8481e-03],
          ...,
          [ 2.1103e-02, -2.9053e-02, -2.8406e-02,  ...,  1.6672e-02,
            1.1989e-02,  3.1817e-03],
          [ 1.5619e-03,  9.6684e-03, -4.2605e-03,  ...,  1.2745e-02,
           -2.8353e-03,  3.5527e-04],
          [-7.2951e-03, -3.7740e-03, -1.2901e-02,  ..., -6.9473e-03,
            1.7153e-03,  2.9245e-03]]],
        [[[ 2.0926e-03,  9.5328e-03,  1.1734e-03,  ...,  1.5732e-03,
           -4.5839e-03, -2.3970e-03],
          [ 6.6905e-03, -8.1619e-03,  1.8898e-02,  ...,  1.9223e-02,
           -4.0052e-03, -2.3419e-03],
          [-2.3826e-03,  1.1627e-02, -3.6279e-03,  ...,  1.6618e-03,
            6.0942e-03,  1.1803e-02],
          ...,
          [ 8.9643e-03, -1.5519e-02,  6.0279e-03,  ..., -1.0572e-02,
            1.4470e-04, -1.5513e-03],
          [-5.8905e-03, -1.5961e-02, -1.3300e-03,  ...,  1.9640e-02,
            9.9501e-03,  4.4209e-04],
          [ 2.1560e-03, -2.4431e-03,  2.5037e-03,  ...,  3.9705e-04,
           -5.8482e-04, -1.0040e-03]],
         [[-1.3436e-03, -2.3728e-03,  6.5991e-03,  ...,  3.7566e-03,
           -4.3254e-03, -5.5019e-03],
          [ 4.6158e-03,  2.8756e-04, -1.4798e-02,  ..., -1.8683e-03,
           -6.9626e-03, -3.1684e-03],
          [-1.0942e-02, -1.9444e-02, -1.4005e-02,  ..., -1.1700e-02,
           -1.1690e-02, -2.3452e-03],
          ...,
          [-2.5658e-03, -1.9222e-02, -3.0572e-02,  ...,  1.1731e-02,
           -1.5906e-02, -8.9043e-04],
          [-1.0143e-02, -1.0786e-02, -5.4850e-03,  ...,  4.0052e-03,
            1.5392e-02,  1.1253e-03],
          [-2.1407e-02, -7.6111e-03,  1.5516e-03,  ...,  2.8289e-03,
           -3.1224e-03,  8.0444e-04]],
         [[-3.5895e-04, -4.7865e-03, -4.4897e-03,  ...,  6.9847e-03,
           -8.1163e-03, -9.2594e-03],
          [ 5.3073e-03, -8.2416e-03,  2.6989e-02,  ..., -2.0176e-02,
            8.5055e-03, -9.6216e-03],
          [ 4.8410e-03, -1.3227e-02, -6.5631e-03,  ..., -1.3117e-02,
            1.4016e-02,  2.7920e-03],
          ...,
          [ 2.2492e-02, -2.4885e-02, -2.4333e-02,  ...,  8.5644e-03,
            6.3045e-03,  3.0865e-03],
          [-1.2646e-03,  4.0035e-03, -3.7116e-03,  ...,  1.2139e-02,
           -2.4430e-03,  1.1709e-03],
          [-7.7473e-03, -4.1869e-04, -9.9477e-03,  ..., -4.3086e-03,
            4.3964e-04,  2.4815e-03]]]], device='cuda:1',
       grad_fn=<GatherBackward>)
[?2004h(Pdb) self.fake_B[0]
tensor([[[ 1.2902e-03,  1.0815e-02,  6.8373e-04,  ...,  9.5553e-04,
          -3.7607e-03, -3.1917e-03],
         [ 6.4032e-03, -5.7597e-03,  1.5315e-02,  ...,  1.9793e-02,
          -5.4536e-04, -3.4145e-03],
         [-1.2168e-03,  1.1389e-02, -1.3378e-03,  ...,  3.4824e-03,
           6.6835e-03,  1.3621e-02],
         ...,
         [ 6.9668e-03, -1.1563e-02,  1.8775e-03,  ..., -1.0910e-02,
          -3.5259e-03, -1.4522e-03],
         [-3.5996e-03, -2.6105e-02, -1.0814e-03,  ...,  2.4250e-02,
           5.2571e-03,  1.1525e-04],
         [ 1.7792e-03, -2.7617e-03,  1.5920e-03,  ...,  1.6205e-03,
          -2.1714e-03, -1.4928e-03]],
        [[-1.4385e-04,  6.7119e-04,  7.0559e-03,  ...,  2.0082e-03,
          -2.9971e-03, -7.2816e-03],
         [ 2.1178e-03,  7.3012e-04, -1.4821e-02,  ...,  8.9955e-05,
          -1.0242e-02, -7.0947e-04],
         [-7.6067e-03, -1.8224e-02, -9.4410e-03,  ..., -1.7001e-02,
          -1.6991e-02, -3.1731e-03],
         ...,
         [ 5.1037e-03, -1.8670e-02, -3.3929e-02,  ...,  1.8082e-02,
          -1.6420e-02, -1.8611e-03],
         [-1.0862e-02, -1.1919e-02, -3.1962e-03,  ...,  8.6255e-03,
           1.3440e-02,  1.1923e-03],
         [-1.9189e-02, -9.0018e-03, -1.2524e-03,  ...,  3.3666e-03,
          -5.6108e-03,  3.9099e-04]],
        [[-7.2490e-04, -4.2398e-03, -5.8729e-03,  ...,  5.5979e-03,
          -1.0596e-02, -1.0230e-02],
         [ 7.0373e-03, -4.7690e-03,  2.8311e-02,  ..., -2.5542e-02,
           1.2273e-02, -1.1982e-02],
         [ 1.7888e-03, -1.0186e-02, -1.0150e-02,  ..., -1.7447e-02,
           1.6524e-02,  2.8481e-03],
         ...,
         [ 2.1103e-02, -2.9053e-02, -2.8406e-02,  ...,  1.6672e-02,
           1.1989e-02,  3.1817e-03],
         [ 1.5619e-03,  9.6684e-03, -4.2605e-03,  ...,  1.2745e-02,
          -2.8353e-03,  3.5527e-04],
         [-7.2951e-03, -3.7740e-03, -1.2901e-02,  ..., -6.9473e-03,
           1.7153e-03,  2.9245e-03]]], device='cuda:1',
       grad_fn=<SelectBackward0>)
[?2004h(Pdb) [?2004l
[?2004h(Pdb) [?2004l
Traceback (most recent call last):
  File "train.py", line 126, in <module>
    model.optimize_parameters()
  File "/home/guest1/ellen_code/pytorch-CycleGAN-and-pix2pix_ellen/models/cycle_gan_model.py", line 188, in optimize_parameters
    self.set_requires_grad([self.netD_A, self.netD_B], False)  # Ds require no gradients when optimizing Gs9981
  File "/home/guest1/ellen_code/pytorch-CycleGAN-and-pix2pix_ellen/models/cycle_gan_model.py", line 188, in optimize_parameters
    self.set_requires_grad([self.netD_A, self.netD_B], False)  # Ds require no gradients when optimizing Gs9981
  File "/home/guest1/.conda/envs/ellen/lib/python3.7/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/home/guest1/.conda/envs/ellen/lib/python3.7/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
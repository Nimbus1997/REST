----------------- Options ---------------
               batch_size: 4                             	[default: 2]
                    beta1: 0.5                           
          checkpoints_dir: ./checkpoints                 
           continue_train: False                         
                crop_size: 512                           	[default: 256]
                 dataroot: /home/ellen/data/input_eyeq_20220830_512_n1000	[default: None]
             dataset_mode: unaligned                     
                direction: AtoB                          
              display_env: main                          
             display_freq: 400                           
               display_id: 1                             
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: lsgan                         
                  gpu_ids: 1                             	[default: 0]
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
                 lambda_A: 10.0                          
                 lambda_B: 10.0                          
          lambda_identity: 0.5                           
                load_iter: 0                             	[default: 0]
                load_size: 512                           	[default: 286]
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: linear                        
         max_dataset_size: inf                           
                    model: cycle_gan                     
                 n_epochs: 100                           
           n_epochs_decay: 300                           
               n_layers_D: 3                             
                     name: ellen_dwt_uresnet2_1_eyeq512_0830	[default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: ellen_dwt_uresnet2_1          	[default: resnet_9blocks]
                      ngf: 64                            
               no_dropout: True                          
                  no_flip: True                          	[default: False]
                  no_html: False                         
                     norm: instance                      
              num_threads: 2                             
                output_nc: 3                             
                 patience: 10                            	[default: 5]
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               
               print_freq: 100                           
             save_by_iter: False                         
          save_epoch_freq: 5                             
         save_latest_freq: 5000                          
           serial_batches: False                         
                   suffix:                               
         update_html_freq: 1000                          
                use_wandb: True                          	[default: False]
                  verbose: False                         
----------------- End -------------------
dataset [UnalignedDataset] was created
The number of training images = 600
dataset [UnalignedDataset] was created
patience: 10
========================================================================
num downs =  2  n_blocks= 9
----e1
-----resnet 0  번째
-----resnet 1  번째
-----resnet 2  번째
-----resnet 3  번째
-----resnet 4  번째
-----resnet 5  번째
-----resnet 6  번째
-----resnet 7  번째
-----resnet 8  번째
>> in, out:  128.0 ,  256
----- e1+unet+resent+uent+
----- e1+unet+resent+uent+d1
[ReflectionPad2d((3, 3, 3, 3)), Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1)), InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False), ReLU(inplace=True), UnetSkipConnectionBlock(
  (model): Sequential(
    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): UnetSkipConnectionBlock(
      (model): Sequential(
        (0): LeakyReLU(negative_slope=0.2, inplace=True)
        (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): UnetSkipConnectionBlock(
          (model): Sequential(
            (0): LeakyReLU(negative_slope=0.2, inplace=True)
            (1): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
            (2): ReLU(inplace=True)
            (3): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
            (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): ReLU(inplace=True)
        (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (2): ReLU(inplace=True)
    (3): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (4): Tanh()
  )
), ReflectionPad2d((3, 3, 3, 3)), Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1)), Tanh()]
initialize network with normal
========================================================================
num downs =  2  n_blocks= 9
----e1
-----resnet 0  번째
-----resnet 1  번째
-----resnet 2  번째
-----resnet 3  번째
-----resnet 4  번째
-----resnet 5  번째
-----resnet 6  번째
-----resnet 7  번째
-----resnet 8  번째
>> in, out:  128.0 ,  256
----- e1+unet+resent+uent+
----- e1+unet+resent+uent+d1
[ReflectionPad2d((3, 3, 3, 3)), Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1)), InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False), ReLU(inplace=True), UnetSkipConnectionBlock(
  (model): Sequential(
    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): UnetSkipConnectionBlock(
      (model): Sequential(
        (0): LeakyReLU(negative_slope=0.2, inplace=True)
        (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): UnetSkipConnectionBlock(
          (model): Sequential(
            (0): LeakyReLU(negative_slope=0.2, inplace=True)
            (1): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
            (2): ReLU(inplace=True)
            (3): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
            (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): ReLU(inplace=True)
        (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (2): ReLU(inplace=True)
    (3): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (4): Tanh()
  )
), ReflectionPad2d((3, 3, 3, 3)), Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1)), Tanh()]
initialize network with normal
initialize network with normal
initialize network with normal
model [CycleGANModel] was created
---------- Networks initialized -------------
[Network G_A] Total number of parameters : 5.959 M
[Network G_B] Total number of parameters : 5.959 M
[Network D_A] Total number of parameters : 2.765 M
[Network D_B] Total number of parameters : 2.765 M
-----------------------------------------------/home/user/miniconda/lib/python3.8/site-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/user/miniconda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
Setting up a new session...
wandb: Currently logged in as: ellen. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /home/ellen/RetinaImage_model_MW/wandb/run-20220830_052942-ckg34g0v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ellen_dwt_uresnet2_1_eyeq512_0830
wandb: ⭐️ View project at https://wandb.ai/ellen/CycleGAN-and-pix2pix
wandb: 🚀 View run at https://wandb.ai/ellen/CycleGAN-and-pix2pix/runs/ckg34g0v

create web directory ./checkpoints/ellen_dwt_uresnet2_1_eyeq512_0830/web...
learning rate 0.0002000 -> 0.0002000
/home/user/miniconda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
(epoch: 1, iters: 100, time: 0.324, data: 0.136) D_A: 0.555 G_A: 1.158 cycle_A: 7.039 idt_A: 1.800 D_B: 1.387 G_B: 1.791 cycle_B: 1.963 idt_B: 1.758 
(epoch: 1, iters: 200, time: 0.328, data: 0.005) D_A: 0.298 G_A: 0.373 cycle_A: 3.112 idt_A: 1.148 D_B: 0.372 G_B: 0.352 cycle_B: 1.319 idt_B: 0.822 
(epoch: 1, iters: 300, time: 0.329, data: 0.005) D_A: 0.274 G_A: 0.339 cycle_A: 4.623 idt_A: 1.521 D_B: 0.365 G_B: 0.506 cycle_B: 1.664 idt_B: 1.082 
(epoch: 1, iters: 400, time: 1.037, data: 0.005) D_A: 0.265 G_A: 0.363 cycle_A: 2.178 idt_A: 0.966 D_B: 0.290 G_B: 0.428 cycle_B: 1.211 idt_B: 0.505 
(epoch: 1, iters: 500, time: 0.332, data: 0.004) D_A: 0.245 G_A: 0.381 cycle_A: 2.661 idt_A: 2.271 D_B: 0.251 G_B: 0.592 cycle_B: 2.457 idt_B: 0.596 
(epoch: 1, iters: 600, time: 0.332, data: 0.008) D_A: 0.268 G_A: 0.364 cycle_A: 1.733 idt_A: 1.026 D_B: 0.309 G_B: 0.281 cycle_B: 1.241 idt_B: 0.386 
End of epoch 1 / 400 	 Time Taken: 204 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 2, iters: 100, time: 0.331, data: 0.209) D_A: 0.245 G_A: 0.299 cycle_A: 2.787 idt_A: 1.264 D_B: 0.284 G_B: 0.276 cycle_B: 1.327 idt_B: 0.721 
(epoch: 2, iters: 200, time: 1.096, data: 0.010) D_A: 0.278 G_A: 0.384 cycle_A: 1.802 idt_A: 0.573 D_B: 0.390 G_B: 0.307 cycle_B: 0.659 idt_B: 0.364 
(epoch: 2, iters: 300, time: 0.331, data: 0.005) D_A: 0.233 G_A: 0.228 cycle_A: 3.394 idt_A: 0.924 D_B: 0.251 G_B: 0.556 cycle_B: 1.017 idt_B: 0.893 
(epoch: 2, iters: 400, time: 0.331, data: 0.005) D_A: 0.307 G_A: 0.406 cycle_A: 1.533 idt_A: 0.883 D_B: 0.340 G_B: 0.211 cycle_B: 1.058 idt_B: 0.308 
(epoch: 2, iters: 500, time: 0.332, data: 0.005) D_A: 0.206 G_A: 0.286 cycle_A: 1.764 idt_A: 1.113 D_B: 0.281 G_B: 0.400 cycle_B: 1.314 idt_B: 0.346 
(epoch: 2, iters: 600, time: 0.760, data: 0.005) D_A: 0.273 G_A: 0.352 cycle_A: 2.809 idt_A: 1.400 D_B: 0.239 G_B: 0.351 cycle_B: 1.447 idt_B: 0.643 
End of epoch 2 / 400 	 Time Taken: 206 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 3, iters: 100, time: 0.330, data: 0.176) D_A: 0.225 G_A: 0.403 cycle_A: 4.325 idt_A: 1.699 D_B: 0.290 G_B: 0.256 cycle_B: 1.759 idt_B: 1.027 
(epoch: 3, iters: 200, time: 0.330, data: 0.007) D_A: 0.286 G_A: 0.248 cycle_A: 2.659 idt_A: 1.597 D_B: 0.271 G_B: 0.220 cycle_B: 1.720 idt_B: 0.599 
(epoch: 3, iters: 300, time: 0.333, data: 0.005) D_A: 0.279 G_A: 0.212 cycle_A: 1.847 idt_A: 1.542 D_B: 0.297 G_B: 0.222 cycle_B: 1.601 idt_B: 0.402 
(epoch: 3, iters: 400, time: 1.203, data: 0.006) D_A: 0.124 G_A: 0.679 cycle_A: 4.633 idt_A: 0.949 D_B: 0.248 G_B: 0.544 cycle_B: 0.878 idt_B: 1.106 
(epoch: 3, iters: 500, time: 0.331, data: 0.005) D_A: 0.164 G_A: 0.415 cycle_A: 1.240 idt_A: 1.244 D_B: 0.246 G_B: 0.518 cycle_B: 1.257 idt_B: 0.279 
(epoch: 3, iters: 600, time: 0.331, data: 0.006) D_A: 0.323 G_A: 0.160 cycle_A: 3.277 idt_A: 1.287 D_B: 0.240 G_B: 0.290 cycle_B: 1.428 idt_B: 0.825 
End of epoch 3 / 400 	 Time Taken: 205 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 4, iters: 100, time: 0.331, data: 0.212) D_A: 0.401 G_A: 0.348 cycle_A: 3.242 idt_A: 0.805 D_B: 0.283 G_B: 0.287 cycle_B: 1.118 idt_B: 0.640 
(epoch: 4, iters: 200, time: 1.265, data: 0.005) D_A: 0.296 G_A: 0.194 cycle_A: 2.311 idt_A: 0.900 D_B: 0.366 G_B: 0.317 cycle_B: 1.053 idt_B: 0.552 
(epoch: 4, iters: 300, time: 0.330, data: 0.005) D_A: 0.240 G_A: 0.371 cycle_A: 2.041 idt_A: 2.744 D_B: 0.163 G_B: 0.408 cycle_B: 2.874 idt_B: 0.408 
(epoch: 4, iters: 400, time: 0.331, data: 0.005) D_A: 0.257 G_A: 0.284 cycle_A: 3.257 idt_A: 1.799 D_B: 0.215 G_B: 0.526 cycle_B: 1.892 idt_B: 0.767 
(epoch: 4, iters: 500, time: 0.331, data: 0.010) D_A: 0.229 G_A: 0.289 cycle_A: 5.796 idt_A: 0.945 D_B: 0.262 G_B: 0.466 cycle_B: 1.063 idt_B: 1.431 
(epoch: 4, iters: 600, time: 0.844, data: 0.010) D_A: 0.179 G_A: 0.428 cycle_A: 3.744 idt_A: 0.803 D_B: 0.221 G_B: 0.348 cycle_B: 0.896 idt_B: 0.924 
End of epoch 4 / 400 	 Time Taken: 207 sec
learning rate 0.0002000 -> 0.0002000

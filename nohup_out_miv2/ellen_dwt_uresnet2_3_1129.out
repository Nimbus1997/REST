----------------- Options ---------------
               batch_size: 32                            	[default: 2]
                    beta1: 0.5                           
          checkpoints_dir: ./checkpoints                 
           continue_train: False                         
                crop_size: 256                           
                 dataroot: /root/jieunoh/ellen_data/input_eyeq_20220830_512_n1000	[default: None]
             dataset_mode: unaligned                     
                direction: AtoB                          
              display_env: main                          
             display_freq: 400                           
               display_id: 1                             
            display_ncols: 4                             
             display_port: 8888                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: lsgan                         
                  gpu_ids: 0,1,2,3,4,5,6,7               	[default: 0]
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
                 lambda_A: 10.0                          
                 lambda_B: 10.0                          
          lambda_identity: 0.5                           
                load_iter: 0                             	[default: 0]
                load_size: 256                           	[default: 286]
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: linear                        
         max_dataset_size: inf                           
                    model: cycle_gan                     
                 n_epochs: 200                           
           n_epochs_decay: 200                           
               n_layers_D: 3                             
                     name: ellen_dwt_uresnet2_3_1129     	[default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: ellen_dwt_uresnet2_3          	[default: resnet_9blocks]
                      ngf: 64                            
               no_dropout: True                          
                  no_flip: True                          	[default: False]
                  no_html: False                         
                     norm: instance                      
              num_threads: 2                             
                output_nc: 3                             
                 patience: 10                            	[default: 5]
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               
               print_freq: 100                           
             save_by_iter: False                         
          save_epoch_freq: 5                             
         save_latest_freq: 5000                          
           serial_batches: False                         
                   suffix:                               
         update_html_freq: 1000                          
                use_wandb: True                          	[default: False]
                  verbose: False                         
----------------- End -------------------
dataset [UnalignedDataset] was created
The number of training images = 600
dataset [UnalignedDataset] was created
patience: 10
========================================================================
num downs =  2  n_blocks= 9
----e1
-----resnet 0  ë²ˆì§¸
-----resnet 1  ë²ˆì§¸
-----resnet 2  ë²ˆì§¸
-----resnet 3  ë²ˆì§¸
-----resnet 4  ë²ˆì§¸
-----resnet 5  ë²ˆì§¸
-----resnet 6  ë²ˆì§¸
-----resnet 7  ë²ˆì§¸
-----resnet 8  ë²ˆì§¸
>> in, out:  128.0 ,  256
----- e1+unet+resent+uent+
----- e1+unet+resent+uent+d1
[ReflectionPad2d((3, 3, 3, 3)), Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1)), InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False), ReLU(inplace=True), UnetSkipConnectionBlock(
  (model): Sequential(
    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): UnetSkipConnectionBlock(
      (model): Sequential(
        (0): LeakyReLU(negative_slope=0.2, inplace=True)
        (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): UnetSkipConnectionBlock(
          (model): Sequential(
            (0): LeakyReLU(negative_slope=0.2, inplace=True)
            (1): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
            (2): ReLU(inplace=True)
            (3): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
            (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): ReLU(inplace=True)
        (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (2): ReLU(inplace=True)
    (3): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (4): Tanh()
  )
), ReflectionPad2d((3, 3, 3, 3)), Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1)), Tanh()]
initialize network with normal
========================================================================
num downs =  2  n_blocks= 9
----e1
-----resnet 0  ë²ˆì§¸
-----resnet 1  ë²ˆì§¸
-----resnet 2  ë²ˆì§¸
-----resnet 3  ë²ˆì§¸
-----resnet 4  ë²ˆì§¸
-----resnet 5  ë²ˆì§¸
-----resnet 6  ë²ˆì§¸
-----resnet 7  ë²ˆì§¸
-----resnet 8  ë²ˆì§¸
>> in, out:  128.0 ,  256
----- e1+unet+resent+uent+
----- e1+unet+resent+uent+d1
[ReflectionPad2d((3, 3, 3, 3)), Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1)), InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False), ReLU(inplace=True), UnetSkipConnectionBlock(
  (model): Sequential(
    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): UnetSkipConnectionBlock(
      (model): Sequential(
        (0): LeakyReLU(negative_slope=0.2, inplace=True)
        (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): UnetSkipConnectionBlock(
          (model): Sequential(
            (0): LeakyReLU(negative_slope=0.2, inplace=True)
            (1): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
            (2): ReLU(inplace=True)
            (3): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
            (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): ReLU(inplace=True)
        (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (2): ReLU(inplace=True)
    (3): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (4): Tanh()
  )
), ReflectionPad2d((3, 3, 3, 3)), Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1)), Tanh()]
initialize network with normal
initialize network with normal
initialize network with normal
model [CycleGANModel] was created
---------- Networks initialized -------------
[Network G_A] Total number of parameters : 5.410 M
[Network G_B] Total number of parameters : 5.410 M
[Network D_A] Total number of parameters : 2.765 M
[Network D_B] Total number of parameters : 2.765 M
-----------------------------------------------/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
Setting up a new session...
wandb: Currently logged in as: z-eun. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /root/jieunoh/ellen_code/RetinaImage_model_MW/wandb/run-20221129_121911-39459fwu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ellen_dwt_uresnet2_3_1129
wandb: â­ï¸ View project at https://wandb.ai/z-eun/CycleGAN-and-pix2pix
wandb: ðŸš€ View run at https://wandb.ai/z-eun/CycleGAN-and-pix2pix/runs/39459fwu

create web directory ./checkpoints/ellen_dwt_uresnet2_3_1129/web...
learning rate 0.0002000 -> 0.0002000
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
